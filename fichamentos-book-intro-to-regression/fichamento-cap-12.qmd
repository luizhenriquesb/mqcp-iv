---
title: "Fichamento Expositivo - Regressão Múltipla (capítulo 12)"
subtitle: "Livro: Galdino, Manoel. Regressão Múltipla (capítulo 12). In: _______. Introdução à Regressão para Ciências Sociais"
format: html
editor: visual
---

```{r setup, include=FALSE}
knitr::opts_knit$set(root.dir = here::here())
```

::: {style="text-align: justify"}

### Carregando pacotes

```{r, message=FALSE, warning=FALSE}
library(tidyverse)
library(knitr)
library(here)
library(tidyr)
```

### 12. Regressão múltipla

Esse capítulo explora a regressão linear múltipla usando R, mas sem entrar em detalhes de como os cálculos são feitos usando álgebra linear. Em vez disso, ele foca nas intuições por trás do uso de vetores e matrizes para representar o modelo de regressão. Especificamente, ele descreve como expressar a regressão linear múltipla na forma matricial.

#### 12.1 Revisão de Matriz e Vetores

Se eu tenho um vetor $x = [ a_1, a_2, ..., a_n]$, digo que este é um vetor linha com $n$ elementos. É possível também ter um vetor coluna:

$$
\begin{align}
    x &= \begin{bmatrix}
           a_{1} \\
           a_{2} \\
           \vdots \\
           a_{n}
         \end{bmatrix}
\end{align}
$$

**Soma de vetores**

Podemos somar dois vetores linhas ou dois vetores colunas, se tiverem o mesmo número de elementos.

$$
  \begin{align}
          \begin{bmatrix}
           a_{1} \\           
           \vdots \\
           a_{n}
          \end{bmatrix} +
          \begin{bmatrix}
           b_{1} \\
           \vdots \\
           b_{n}
         \end{bmatrix}
    &= \begin{bmatrix}
           a_1 + b_{1} \\           
           \vdots \\
           a_n + b_{n}
          \end{bmatrix}     
  \end{align}
$$

**Multiplicação de vetores**

Podemos fazer a multiplicação de vetores (existem vários tipos, aqui me restringo ao produto interno ou produto ponto de vetores), desde que a gente multiplique um vetor linha por uma vetor coluna, mas não o contrário.

$$
  \begin{align}
          \begin{bmatrix}
           a_{1}, a_2, \cdots, a_{n}
          \end{bmatrix} \cdot
          \begin{bmatrix}
           b_{1} \\
           b_{2} \\
           \vdots \\
           b_{n}
         \end{bmatrix}
    &=  a_1 \cdot b_{1} + a_2 \cdot b_2 \cdots + a_n \cdot b_{n} 
  \end{align}
$$

A razão é que a multiplicação de vetores (e matrizes em geral) é basicamente multiplicar linha com coluna.

#### 12.2 Modelo Básico \[de regressão linear múltipla\]

O modelo básico de regressão linear múltipla pode ser especificado por:

1.  Existem p preditores, $X_1$, $X_2$, ..., $X_p$. Não precisamos fazer suposições sobre a distribuição dos preditores, e podem ser correlacionados ou não.

2.  Há uma única variável resposta, $Y$. Se houvesse mais de uma, teríamos um modelo de regressão multivariada.

3.  $y_i = \alpha + \beta_1 \cdot x_{1i} + \beta_2 \cdot x_{2i} + ... + \beta_p \cdot x_{pi} + e_i$. Portanto, temos $p+1$ parâmetros ou coeficientes de regressão a estimar.

4.  O erro $e_i$ possui esperança condicional zero e variância condicional constante no modelo homocedástico, e não correlacionado entre observações.

Se assumirmos normalidade do termo de erro, temos também:

5.  O erro $e_i$ tem uma distribuição normal multivariada, com vetor de médias zero e matriz de variância e covariância cujos elementos fora da diagonal (covariância) são zero, e a diagonal principal é $\sigma^2$.\]

#### 12.3 Modelo com matrizes
